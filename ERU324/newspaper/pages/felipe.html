<div>

    <p>
        A inteligência artificial (IA) está revolucionando diversos setores da sociedade, desde a medicina até a
        indústria. No entanto, como qualquer ferramenta poderosa, ela também pode ser utilizada para fins maliciosos.
        Nas mãos de golpistas, a IA torna-se uma arma formidável, capaz de criar golpes mais sofisticados e difíceis de
        detectar.
    </p>

    <figure class="figure">
        <img class="media fullmedia" src="public/hacker.gif" alt="">
        <figcaption class="figcaption">Hacker Meme. 2015. Disponível
            em:
            <a href="https://imgur.com/gallery/hDOfuOx" target="_blank">https://imgur.com/gallery/hDOfuOx</a>.
            Acesso em:
            02 abr. 2024.
        </figcaption>
    </figure>

    <p>
        Tecnologias emergentes vêm se tornando cada vez mais presentes em ataques executados por cibercriminosos. Eles,
        normalmente, fazem uso de modelos generativos para criar, modificar e aperfeiçoar o ataque. São capazes de gerar
        vídeos e áudio da vítima a partir de fotos e gravações. Além de vasculhar o contexto em que esta se insere para
        melhorar a veracidade do golpe.
    </p>

    <span class="subtopic">
        Deepfakes: enganando com a tecnologia
    </span>

    <p>
        Um dos exemplos mais assustadores do uso da IA para golpes é a criação de deepfakes. São vídeos manipulados que
        simulam a fala e os gestos de pessoas reais com um nível de realismo impressionante. Em 2020, um deepfake do
        diretor
        de uma empresa japonesa foi utilizado para convencer funcionários a realizar transferências bancárias,
        resultando em
        um prejuízo de US$ 35 milhoẽs. Imagine receber um vídeo do seu chefe pedindo para realizar uma transferência
        urgente. Se o vídeo for convincente o suficiente, você pode acabar caindo no golpe. Os criminosos agem baseados
        no
        censo de alarde dos funcionários, tentado criar uma situação de pânico em que a vítima não seja capaz de agir
        racionalmente, e sim com base nos instintos.
    </p>

    <span class="subtopic">
        Phishing personalizado: mensagens sob medida
    </span>

    <p>
        Não obstante, a IA também permite a criação de e-mails e mensagens de phishing altamente personalizadas. Graças
        aos
        avanços na geração de texto, chatbots e deep learning, criminosos agora podem automatizar e escalar seus
        esquemas
        fraudulentos de maneiras nunca antes imaginadas. Os Large Language Models (LLMs) são capazes de redigir textos
        em
        diversas línguas e estilos de texto, eles podem ser treinados para ler todos os perfis de redes sociais, como o
        LinkedIn, e com isso entender o contexto em que a vítima se encontra. Dessa forma, ele é capaz de identificar
        superiores, amigos, colegas de trabalho, projetos executados pela vítima, dentre outros. Gerando finalmente, um
        phishing mais convincente e eficaz contra o funcionário.

    </p>

    <span class="subtopic">
        IA a serviço do crime: análise de dados para identificar vítimas
    </span>

    <p>

        Golpistas estão usando IA para analisar dados de vítimas em potencial, como histórico de compras e comportamento
        online, para identificar alvos mais propensos a cair em golpes. Imagine um golpista que tem acesso a um banco de
        dados com informações sobre suas compras online, seus hábitos de navegação na internet e suas redes sociais. Com
        essa informação, ele pode criar um golpe sob medida para você, aumentando consideravelmente as chances de
        sucesso.
    </p>

    <span class="subtopic">
        Exemplos reais de golpes com IA:
    </span>

    <p>

        Deepfakes: Em 2022, um deepfake da voz de um gerente de banco foi usado para convencer um cliente a transferir
        dinheiro para uma conta fraudulenta. O golpista utilizou uma tecnologia de IA para imitar a voz do gerente e
        ligou
        para a vítima, fingindo ser ele. A vítima, acreditando que estava falando com o gerente real do seu banco,
        acabou
        transferindo R$ 10 mil para uma conta fraudulenta.

        Conteúdo enganoso: Em 2023, uma campanha de anúncios falsos no Facebook, gerados por IA, induziu pessoas a
        investir
        em um esquema Ponzi. Os anúncios, que prometiam retornos rápidos e altos, utilizavam imagens e textos realistas
        para
        atrair vítimas. As vítimas, acreditando na promessa de lucros fáceis, investiram dinheiro no esquema e perderam
        tudo.
    </p>

    <span class="subtopic">
        Como se proteger na era da IA:
    </span>


    <div>
        <p>Diante de tantos riscos, é fundamental tomar medidas para se proteger contra golpes que utilizam IA. Aqui
            estão algumas dicas:</p>

        <ul>
            <li>Desconfie de ofertas boas demais para ser verdade. Se algo parece bom demais para ser verdade,
                provavelmente é.</li>
            <li>Verifique a autenticidade de remetentes de e-mails e mensagens. Antes de clicar em qualquer link ou
                responder a um e-mail, verifique se o remetente é realmente quem diz ser.</li>
            <li>Passe o mouse sobre links antes de clicar. Ao passar o mouse sobre um link, você pode ver o endereço
                real para onde ele está direcionando. Se o endereço parecer estranho ou suspeito, não clique.</li>
            <li>Mantenha seus softwares e antivírus atualizados. Atualizações de software e antivírus podem incluir
                medidas de proteção contra golpes que utilizam IA.</li>
            <li>Fique atento a notícias falsas e conteúdos enganosos nas redes sociais. Nem tudo que você vê online é
                verdade. Verifique a fonte da informação antes de compartilhar ou acreditar em algo.</li>
            <li>Use ferramentas de segurança online. Existem diversas ferramentas disponíveis que podem ajudar a
                proteger você contra golpes online.</li>
            <li>Sensibilize-se sobre os riscos da IA. É importante entender como a IA pode ser usada para aplicar golpes
                e como se proteger.</li>
        </ul>

        <p>
            <b>
                Lembre-se: a sua segurança online depende de você. Seja vigilante e tome cuidado.
            </b>
        </p>

        <div>
            <span class="subtopic">
                Referências:
            </span><br />


            <figcaption class="figcaption">Você não sabe, mas estes golpes usam IA para enganar você; aprenda a evitar.
                <b>Tilt Uol.</b> 2024. Disponível em: <a
                    href="https://www.uol.com.br/tilt/noticias/redacao/2024/02/21/uso-inteligencia-artificial-golpes-virtuais.htm"
                    target="_blank">https://www.uol.com.br/tilt/noticias/redacao/2024/02/21/uso-inteligencia-artificial-golpes-virtuais.htm</a>.
                Acesso em: 02 abr. 2024.
            </figcaption>

            <figcaption class="figcaption">FraudGPT: o 'irmão' do ChatGPT usado para criar golpes e outras ameaças
                digitais. <b>O Globo.</b> 2024. Disponível em: <a
                    href="https://oglobo.globo.com/economia/tecnologia/noticia/2024/01/21/fraudgpt-o-irmao-do-chatgpt-usado-para-criar-golpes-e-outras-ameacas-digitais.ghtml"
                    target="_blank">https://oglobo.globo.com/economia/tecnologia/noticia/2024/01/21/fraudgpt-o-irmao-do-chatgpt-usado-para-criar-golpes-e-outras-ameacas-digitais.ghtml</a>.
                Acesso em: 02 abr. 2024.</figcaption>

            <figcaption class="figcaption">Golpes digitais ficam mais eficientes com Inteligência Artificial.
                <b>Forbes.</b> 2023. Disponível em: <a
                    href="https://forbes.com.br/forbes-money/2023/09/por-que-a-ia-pode-tornar-os-crimes-digitais-mais-eficientes/"
                    target="_blank">https://forbes.com.br/forbes-money/2023/09/por-que-a-ia-pode-tornar-os-crimes-digitais-mais-eficientes/</a>.
                Acesso em: 02 abr. 2024.
            </figcaption>

            <figcaption class="figcaption">'Eram meu rosto e minha voz, mas era golpe': como criminosos 'clonam pessoas'
                com inteligência artificial. <b>BBC.</b> 2024. Disponível em: <a
                    href="https://www.bbc.com/portuguese/articles/cd1jv45dq3go#:~:text=A%20advogada%20explica%20que%20acredita,sincronizar%20movimentos%20labiais%20e%20express%C3%B5es"
                    target="_blank">https://www.bbc.com/portuguese/articles/cd1jv45dq3go#:~:text=A%20advogada%20explica%20que%20acredita,sincronizar%20movimentos%20labiais%20e%20express%C3%B5es</a>.
                Acesso em: 02 abr. 2024.</figcaption>

            <figcaption class="figcaption">Anúncios falsos no Google e Facebook fazem usuários perderem dinheiro.
                <b>IG.</b> 2022. Disponível em: <a
                    href="https://tecnologia.ig.com.br/2022-04-15/anuncios-falsos-google-facebook-golpe-perder-dinheiro.html"
                    target="_blank">https://tecnologia.ig.com.br/2022-04-15/anuncios-falsos-google-facebook-golpe-perder-dinheiro.html</a>.
                Acesso em: 02 abr. 2024.
            </figcaption>

            <figcaption class="figcaption">Golpistas usam técnica de deepfake para acessar aplicativos de bancos e
                furtar. <b>G1.</b> 2022. Disponível em: <a
                    href="https://g1.globo.com/ms/mato-grosso-do-sul/noticia/2022/12/15/golpistas-usam-tecnica-de-deepfake-para-acessar-aplicativos-de-bancos-e-furtar-especialista-da-dicas-de-protecao.ghtml"
                    target="_blank">https://g1.globo.com/ms/mato-grosso-do-sul/noticia/2022/12/15/golpistas-usam-tecnica-de-deepfake-para-acessar-aplicativos-de-bancos-e-furtar-especialista-da-dicas-de-protecao.ghtml</a>.
                Acesso em: 02 abr. 2024.</figcaption>
        </div>


    </div>
</div>